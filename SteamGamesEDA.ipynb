{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Custom Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Docstring, function converts \"list-like\" to string\n",
    "def unpack_list_like(list_like_series:pd.core.series.Series, asType:str) -> pd.core.series.Series:\n",
    "    \n",
    "    # Remove open and close square brackets, single-quotes, and replace commas with forward slashes\n",
    "    unpacked_series = (list_like_series.str.replace(\"[\",\"\")\n",
    "                       .str.replace(\"]\",\"\")\n",
    "                       .str.replace(\"', '\",\"/\")\n",
    "                       .str.replace(\"\\'\",\"\"))\n",
    "    \n",
    "    return unpacked_series.astype(asType)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Section 1: Load and Initial Assesment\n",
    "In this section, the DataFrame is loaded in raw format in two zipped parts, and concatenated. The method `.info()` of the DataFrame class is used to gather initial insights about the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the dataset parts into DataFrames and concatenate them into a single DataFrame\n",
    "games_sub1 : pd.core.frame.DataFrame = pd.read_csv(\"datasets/games_may2024_cleaned_1of2.zip\", encoding='latin1', low_memory=False)\n",
    "games_sub2 : pd.core.frame.DataFrame = pd.read_csv(\"datasets/games_may2024_cleaned_2of2.zip\", encoding='latin1', low_memory=False)\n",
    "\n",
    "games_raw : pd.core.frame.DataFrame = pd.concat([games_sub1, games_sub2])\n",
    "\n",
    "# Intitial Assessment (info, memory usage, shape, and head)\n",
    "print(\"=\"*20 + \" DataFrame Information \" + \"=\"*20)\n",
    "games_raw.info()\n",
    "print(\"=\"*20 + \" DataFrame Information \" + \"=\"*20)\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" Memory Usage \" + \"=\"*20)\n",
    "print(f\"{games_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"=\"*20 + \" Memory Usage \" + \"=\"*20)\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" DataFrame Shape \" + \"=\"*20)\n",
    "print(games_raw.shape)\n",
    "print(\"=\"*20 + \" DataFrame Shape \" + \"=\"*20)\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" DataFrame Head \" + \"=\"*20)\n",
    "print(games_raw.head())\n",
    "print(\"=\"*20 + \" DataFrame Head \" + \"=\"*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Section 2: Data Quality Assessment\n",
    "In this section, the data values are examined to inform cleaning decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of NA values in each column\n",
    "print(\"\\n\" + \"=\"*20 + \" NA Values\" + \"=\"*20)\n",
    "print(games_raw.isna().sum())\n",
    "print(\"=\"*20 + \" NA Values \" + \"=\"*20)\n",
    "\n",
    "# Find the number of unique values in each column\n",
    "print(\"\\n\" + \"=\"*20 + \" Unique Values \" + \"=\"*20)\n",
    "print(games_raw.nunique())\n",
    "print(\"=\"*20 + \" Unique Values \" + \"=\"*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Section 3: Cleaning Decisions\n",
    "In this section, the DataFrame is cleaned based on the analysis of the previous section, as well as the return of the `.head()` method in Section 1. Section 1 is used to inform type casting decisions, and Section 2 is used to provide early warning of type casting errors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Drop Unwanted Columns:\n",
    "Columns that do not contribute to analysis of the dataset or aid in answering the question are dropped from the DataFrame in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns from the dataframe using the .drop() method\n",
    "games = games_raw.drop(columns=[\"required_age\",\n",
    "                              \"dlc_count\",\n",
    "                              \"detailed_description\", \n",
    "                              \"about_the_game\", \n",
    "                              \"short_description\", \n",
    "                              \"reviews\", \n",
    "                              \"support_url\", \n",
    "                              \"support_email\", \n",
    "                              \"estimated_owners\",\n",
    "                              \"metacritic_score\", \n",
    "                              \"metacritic_url\", \n",
    "                              \"achievements\", \n",
    "                              \"recommendations\", \n",
    "                              \"notes\",\n",
    "                              \"full_audio_languages\",\n",
    "                              \"packages\",\n",
    "                              \"categories\",  \n",
    "                              \"screenshots\", \n",
    "                              \"movies\",\n",
    "                              \"user_score\", \n",
    "                              \"score_rank\", \n",
    "                              \"tags\",\n",
    "                              \"pct_pos_total\",\n",
    "                              \"pct_pos_recent\",\n",
    "                              \"average_playtime_forever\", \n",
    "                              \"average_playtime_2weeks\", \n",
    "                              \"median_playtime_forever\",\n",
    "                              \"median_playtime_2weeks\", \n",
    "                              \"header_image\", \n",
    "                              \"website\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Set the Index:\n",
    "In Section 2, it was found that the column \"AppID\" has _nearly_ the same number of unique values (83653) as the number of rows (83655), making this a great index option. Furtheremore, this column has 0 NA values. For these reasons, \"AppID\" was selected as the index. Some values were found with clear encoding errors, these were scrapped in the process, as all columns in those rows were improperly encoded, and thus unusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index:\n",
    "# Cast the \"AppID\" column to numeric (NA if not numeric-like) and drop rows with NA values\n",
    "games['AppID'] = pd.to_numeric(games['AppID'], downcast='integer', errors='coerce')\n",
    "games = games.dropna(subset=[\"AppID\"])\n",
    "\n",
    "# Convert remaining rows' \"AppID\" value to uint32 and then set the index of the DataFrame to this column\n",
    "games[\"AppID\"] = games['AppID'].astype('uint32')\n",
    "\n",
    "# Set the data frame index to the \"AppID\" column\n",
    "games = games.set_index(\"AppID\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Cast Column Data Types:\n",
    "Three main types of columns are converted below:\n",
    "1. Straight-forward string and numeric columns. These are converted to the most appropriate type using `.astype()` with a mapping of column:type pairs as the argument.\n",
    "2. Columns that are \"list-like\" (e.g. \\['English', 'Vietnamese'\\]). These values are modified to be forward slash seperated for subsequent analysis (e.g. English/Vietnamese). Language columns are converted to strings, while genre, developer, and publisher columns are converted to categories due to a high count of repeat values as determined in Section 2.\n",
    "3. Boolean values. The dataset uses \"TRUE\" and \"FALSE\" for its boolean values, which `.astype()` always interprets as True. To solve this problem, each of these columns are initially cast as string, and then are set equal to a boolean mask on the condition `df['col'] == \"TRUE\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert straightforward numeric and string column data types\n",
    "games = games.astype({'name' : 'string',\n",
    "                      'release_date' : 'datetime64[ns]',\n",
    "                      'price' : 'float32',\n",
    "                      'windows' : 'string',\n",
    "                      'mac' : 'string',\n",
    "                      'linux' : 'string',\n",
    "                      'positive' : 'Int64',\n",
    "                      'negative' : 'Int64',\n",
    "                      'peak_ccu' : 'Int64',\n",
    "                      'num_reviews_recent' : 'Int64'\n",
    "                   })\n",
    "\n",
    "# Convert the \"list-like\" columns from ['thing1','thing2'] string to \"thing1/thing2\" category or string\n",
    "games[\"supported_languages\"] = unpack_list_like(games[\"supported_languages\"], asType='string')\n",
    "games['developers'] = unpack_list_like(games[\"developers\"], asType='category')\n",
    "games['publishers'] = unpack_list_like(games[\"publishers\"], asType='category')\n",
    "games['genres'] = unpack_list_like(games[\"genres\"], asType='category')\n",
    "\n",
    "# Set incompatible boolean value columns equal to a bool mask to map TRUE to True and FALSE to False\n",
    "games['windows'] = games['windows'].str.strip() == \"TRUE\"\n",
    "games['mac'] = games['mac'].str.strip() == \"TRUE\"\n",
    "games['linux'] = games['linux'].str.strip() == \"TRUE\"\n",
    "\n",
    "# Report cleaned DataFrame size\n",
    "print(f\"The size of the cleaned DataFrame is {games.memory_usage(deep=True).sum() / 1024**2:.2f}MB\")\n",
    "\n",
    "# Find the number of unique values in each column\n",
    "print(\"\\n\" + \"=\"*20 + \" Unique Values (Cleaned) \" + \"=\"*20)\n",
    "print(games.nunique())\n",
    "print(\"=\"*20 + \" Unique Values (Cleaned) \" + \"=\"*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Section 4: Statistical EDA\n",
    "In this section's subsections, several variables/groups of variables are characterized using statistical measurement and visualization transformations. Performing statistical and visual operations on these values allows their distributions to be understood, which provides insight into the measures and their assocaited values. First, individual features are analyzed, and then relations between various features are explored."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Release Date EDA:\n",
    "The goal of this section is to characterize the `release_date` column statistically and visually to understand how game release frequencies have changed over time. After cleaning this dataset, 83646 valid observations remain. Section 2 revealed that there are only 4503 unique release dates. As such, it becomes evident that a frequency analysis can provide some insight into the frequency distribution of game release dates. Since there are 4503 unique values of day/month/year, Pandas' built-in plotting struggles to handle axis labels, and as a result, these values were temporarily reduced to a year only value, as this alone is sufficient to understand the change in released game counts over time. Note: Logarithmic scale is used for the number of released games (y-axis) to esnure an insightful bar is plotted for early years (pre-2006) with low release counts. In addition to this frequency analysis, the average number of released games in a given year is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new series of the release dates, with dates reduced to year only.\n",
    "release_year_freq = (games['release_date']\n",
    "                     .dt.year\n",
    "                     .value_counts())\n",
    "\n",
    "# Plot the release year frequency using Pandas\n",
    "release_year_freq.sort_index().plot(kind='bar', \n",
    "                                    title=\"Release Year Frequency\", \n",
    "                                    logy=True, xlabel='Release Year', \n",
    "                                    ylabel='Number of Games Released')\n",
    "plt.show()\n",
    "\n",
    "# Show the frequency of game releases, sorted by number of releases\n",
    "print(\"\\n Sorted Game Release Frequency by Year\")\n",
    "print(release_year_freq)\n",
    "\n",
    "# Statistically characterize the release year distribution\n",
    "print(f\"\\nThe average year has approximately {release_year_freq.mean():.1f} games released.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Game Price EDA:\n",
    "The goal of this section is to characterize the price distribution of the games statistically and visually, across the dataset. Here, Pandas' `.describe()` method is used to statistically characterize the distribution of the `price` continuous variable. Furthermore, a logarithmic plot is provided to understand the _entire_ distribution due to the existance of a handful of games in the 975-1000 USD range. Additionally, a histogram is provided in the 0-75 USD range to characterize the _heavy_ majority of the distribution, as shown by the logarithmic plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistically descibe the distribution of the price column\n",
    "print(games['price'].describe())\n",
    "\n",
    "# Plot the entire frequency of prices using a histogram, syncing bins with xticks\n",
    "bins_xticks_range = range(0, 1001, 25)\n",
    "games['price'].plot(kind='hist', \n",
    "                    title=\"Full Logarithmic Frequency Distribution of Game Price\", \n",
    "                    logy=True, \n",
    "                    xlabel=\"Price in USD($)\", \n",
    "                    bins=bins_xticks_range, \n",
    "                    xticks=bins_xticks_range, \n",
    "                    rot=90\n",
    "                   )\n",
    "plt.show()\n",
    "\n",
    "# Plot the reduced frequency of prices using a histogram, syncing bins with xticks\n",
    "bins_xticks_range_reduced = range(0, 80, 5)\n",
    "games['price'].plot(kind='hist', \n",
    "                    title=\"Reduced ($0-75 USD) Frequency Distribution of Game Price\",  \n",
    "                    xlabel=\"Price in USD($)\", \n",
    "                    bins=bins_xticks_range_reduced, \n",
    "                    xticks=bins_xticks_range_reduced, \n",
    "                    rot=90,\n",
    "                    xlim=(0,75)\n",
    "                   )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Operating System Offering EDA:\n",
    "In this section, the operating system offerings of the games in the dataset are analyzed. The counts of games offered on each OS is reported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the counts of each operating systems' games\n",
    "print(f\"Windows has {games['windows'].sum()} games available.\")\n",
    "print(f\"Macintosh has {games['mac'].sum()} games available.\")\n",
    "print(f\"Linux has {games['linux'].sum()} games available.\")\n",
    "\n",
    "games[['windows', 'mac', 'linux']].sum().plot(kind='bar',\n",
    "                                              title=\"Number of Games per OS\",\n",
    "                                              xlabel='Operating System',\n",
    "                                              ylabel='Number of Games Offered',\n",
    "                                              rot=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### User Review (Positive/Negative) EDA:\n",
    "In this section, the number of user reviews (both positive and negative) are statistically analyzed. Additionally, positive and negative reviews are plotted in a single figure to offer a side-by side comparison of the two measures. Note here that the use of the `.describe()` method is primarily used to inform plot parameter selection, and the key takeaways of the statistical measures of these features is restated after the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistically characterize the number of positive reviews\n",
    "print(\"Positive Review Statistics:\")\n",
    "print(games['positive'].describe())\n",
    "\n",
    "# Statistically characterize the number of negative reviews\n",
    "print(\"\\nNegative Review Statistics:\")\n",
    "print(games['negative'].describe())\n",
    "\n",
    "# Plot the histograms of positive and negative reviews in a single figure\n",
    "games.plot(kind='scatter', \n",
    "           x='positive', \n",
    "           y='negative',\n",
    "           xlabel='Positive Reviews',\n",
    "           ylabel='Negative Reviews',\n",
    "           title='Positive vs. Negative Reviews'\n",
    "          )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Bivariate Analysis 1: Average Game Price per Release Year\n",
    "In this section, the average price of games was compared to the release year using `.groupby()` with the `.mean()` aggregation function. Results were plotted as a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column containing the release year as a category\n",
    "games['release_year'] = (games['release_date'].dt.year).astype('category')\n",
    "\n",
    "# Group by year, aggregate price average\n",
    "avg_price_by_year = (games.groupby('release_year', observed=False)['price']\n",
    "                     .mean()\n",
    "                     .sort_index())\n",
    "\n",
    "# Report average price per year\n",
    "print(avg_price_by_year)\n",
    "\n",
    "# Plot the results using a bar graph\n",
    "avg_price_by_year.plot(kind='bar', \n",
    "                       title=\"Average Yearly Game Price\", \n",
    "                       logy=True, \n",
    "                       xlabel='Release Year', \n",
    "                       ylabel='Average Game Price (USD)',\n",
    "                       rot=90.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Bivariate Analysis 2: Operating System Game Releases by Year\n",
    "In this section, the number of released games per operating system were computed for each release year using the `.groupby()` methd with the `.sum()` aggregation function to count results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by year, aggregate count of each OS game releases\n",
    "os_releases_by_year = (games.groupby('release_year', observed=False)[['windows', 'mac', 'linux']]\n",
    "                     .sum()\n",
    "                     .sort_index())\n",
    "\n",
    "# Report average price per year, flattened\n",
    "print(os_releases_by_year.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the precentage positive\n",
    "#create percentage positive column\n",
    "games = games.astype({\"positive\" : \"float64\", \"negative\" : \"float64\"})\n",
    "games.info()\n",
    "games[\"percent_positive\"] = games[\"positive\"] / (games[\"positive\"] + games[\"negative\"])\n",
    "\n",
    "#report average number of positive and negative reviews and average percentage positive\n",
    "rec_year = games.groupby(\"release_year\", observed=False)[[\"positive\", \"negative\", \"percent_positive\"]].mean()\n",
    "print(rec_year)\n",
    "\n",
    "games[\"percent_positive\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at peak ccu\n",
    "# groupby peack ccu to get mean, sum and count for each year\n",
    "year_pccu = games.groupby(\"release_year\", observed=False)[[\"peak_ccu\",\"name\"]].agg(\n",
    "    {\"peak_ccu\" : [\"mean\", \"sum\"],\n",
    "     \"name\" : \"count\"})\n",
    "print(year_pccu)\n",
    "\n",
    "#peak ccu stats\n",
    "print(f'\\nPeak CCU Stats:\\n{games[\"peak_ccu\"].describe()}')\n",
    "\n",
    "#tried looking at developers in relation to peak ccu and it needs cleaning i think\n",
    "#dev_pccu = games.groupby(\"developers\", observed=False)[\"peak_ccu\"].mean().sort_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language stuff\n",
    "\n",
    "\n",
    "## option 1 Split and make lists either make new series or change supported languages\n",
    "#languages =  games[\"supported_languages\"].str.split(\"/\")\n",
    "#### NEEDS TO BE ADDED EARLIER\n",
    "#games[\"supported_languages\"] = games[\"supported_languages\"].str.split(\"/\")\n",
    "\n",
    "\n",
    "## option 2 use str contains and make a series for each interested language\n",
    "#english = games[\"supported_languages\"].str.contains(\"English\")\n",
    "#print(english.sum())\n",
    "\n",
    "## option 3 add a boolean column to for each interested language\n",
    "games[\"English\"] = games[\"supported_languages\"].str.contains(\"English\")\n",
    "games[\"Chinese\"] = games[\"supported_languages\"].str.contains(\"Chinese\")\n",
    "games[\"Japanese\"] = games[\"supported_languages\"].str.contains(\"Japanese\")\n",
    "games[\"Spanish\"] = games[\"supported_languages\"].str.contains(\"Spanish\")\n",
    "games[\"German\"] = games[\"supported_languages\"].str.contains(\"German\")\n",
    "games[\"French\"] = games[\"supported_languages\"].str.contains(\"French\")\n",
    "games[\"Russian\"] = games[\"supported_languages\"].str.contains(\"Russian\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(games[[\"English\",\"Chinese\", \"Japanese\", \"Spanish\", \"German\", \"French\", \"Russian\"]].sum())\n",
    "\n",
    "lang = [\"English\",\"Chinese\", \"Japanese\", \"Spanish\", \"German\", \"French\", \"Russian\"]\n",
    "for x in lang:\n",
    "    print(f'Language: {x}')\n",
    "    print(f'Total {x} games: {games[x].sum()}')\n",
    "    print(f'Average {x} games price: {games[\"price\"].loc[games[x] == True].mean()}')\n",
    "    print(f'Average {x} games peak ccu: {games[\"peak_ccu\"].loc[games[x] == True].mean()}')\n",
    "    print(f'Average {x} games positive reviews: {games[\"positive\"].loc[games[x] == True].mean()}')\n",
    "    print(f'Average {x} games negative reviews: {games[\"negative\"].loc[games[x] == True].mean()}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing developer\n",
    "\n",
    "temp = games[\"publishers\"].isin(games[\"developers\"])\n",
    "print(temp.sum())\n",
    "games[\"dev_pub\"] = games[\"publishers\"].isin(games[\"developers\"])\n",
    "\n",
    "group_price = games.groupby(\"dev_pub\")[[\"price\", \"name\"]].agg({\n",
    "    \"price\" : [\"mean\", \"sum\"],\n",
    "    \"name\" : \"count\"})\n",
    "print(group_price)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Section 5: Transform\n",
    "TODO: \n",
    "\n",
    "Note: These are just suggestions, the key detail is that 3-4 features are engineered and analyzed.\n",
    "\n",
    "1. Feature comparing peak_ccu to the number of supported languages\n",
    "2. Feature relating num recent reviews to peak ccu (called something like review rate)\n",
    "3. Feature for does publisher match developer, then analyze how this affects price (yes v no to see if having different costs more)\n",
    "4. Feature for something like overall value something like price compared to pct positive reviews.\n",
    "Note: You can unhide and type any of the playtime/pct pos reviews/etc. data points in the cells above that you may decide you need for additional feature engineering i.e. remove that col name from the removal list and then give it a float type in the games.astype() block statement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Section 6: Save and Document\n",
    "In this section, the resulting cleaned dataset with additional engineered features is exported as pickle (for Python users) and CSV (for compatability). Note that these files are ignored by Git for tracking since Git is for source code and not exports."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab086447",
   "metadata": {},
   "source": [
    "### Exporting the Cleaned and Feature Engineered Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the dataset to export the AppID along with the rest of the data.\n",
    "games.reset_index()\n",
    "\n",
    "# Export as a Pickle file\n",
    "games.to_pickle(\"exports/games_cleaned_added_features.pkl\")\n",
    "\n",
    "# Export as CSV, removing index since after resetting the index, the index is a simple integer value\n",
    "games.to_csv(\"exports/games_cleaned_added_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
